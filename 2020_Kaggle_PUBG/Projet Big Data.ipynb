{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import *\n",
    "from datetime import datetime\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import du fichier train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "data = pd.read_csv('gdrive/My Drive/train_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-suppression des mauvais données et des colonnes trop corrélés  \n",
    "-renommage des différents types de matchs pour avoir que les 3 souhaités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, subset=['winPlacePerc'])\n",
    "data = data.loc[(data['killPlace'] < 101)]\n",
    "data = data.drop([\"DBNOs\",\"maxPlace\",\"winPoints\"], axis = 1)\n",
    "\n",
    "data.loc[(data['matchType']== 'squad-fpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'normal-squad-fpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'normal-squad'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'flarefpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'flaretpp'),'matchType']='squad'\n",
    "\n",
    "data.loc[(data['matchType']== 'duo-fpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']== 'normal-duo-fpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='normal-duo'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='crashfpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='crashtpp'),'matchType']='duo'\n",
    "\n",
    "data.loc[(data['matchType']== 'solo-fpp'),'matchType']='solo'\n",
    "data.loc[(data['matchType']== 'normal-solo-fpp'),'matchType']='solo'\n",
    "data.loc[(data['matchType']== 'normal-solo'),'matchType']='solo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-kmeans et ajout de la classe dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "datak = data.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "kmeans = KMeans(n_clusters=7, random_state=0,max_iter=10,n_init=1).fit(datak)\n",
    "data['classe']=kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-création de variables pouvant être intéressantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['healParDurationM']=data['heals']/data['matchDuration']\n",
    "data['killParDurationM']=data['kills']/data['matchDuration']\n",
    "data['killParRideDist']=data['kills'].divide(data['rideDistance'])\n",
    "data['RideDistParDurationM']=data['rideDistance']/data['matchDuration']\n",
    "data['BoostParKill']=data['boosts'].divide(data['kills'])\n",
    "data['KillParSwimDist']=data['kills'].divide(data['swimDistance'])\n",
    "data['KillParWalkDist']=data['kills'].divide(data['walkDistance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-création des moyennes et des maximums par match et par groupe  \n",
    "-création de 2 variables de comparaison par rapport au match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=data.drop([\"matchType\",\"Id\",\"groupId\",\"classe\",\"winPlacePerc\"], axis = 1)\n",
    "mean=ok.groupby('matchId').mean()\n",
    "maxi=ok.groupby('matchId').max()\n",
    "\n",
    "\n",
    "mean.columns = [x + \"meanMatch\" for x in mean.columns]\n",
    "maxi.columns = [x + \"maxMatch\" for x in maxi.columns]\n",
    "\n",
    "\n",
    "meanG=ok.groupby('groupId').mean()\n",
    "maxiG=ok.groupby('groupId').max()\n",
    "\n",
    "\n",
    "meanG.columns = [x + \"meanGroupe\" for x in meanG.columns]\n",
    "maxiG.columns = [x + \"maxGroupe\" for x in maxiG.columns]\n",
    "\n",
    "\n",
    "data=data.merge(meanG,on='groupId').merge(maxiG,on='groupId').merge(mean,on='matchId').merge(maxi,on='matchId')\n",
    "\n",
    "\n",
    "data = pd.get_dummies(data, columns=['classe'])\n",
    "data=data.replace([inf], np.nan)\n",
    "data=data.fillna(0)\n",
    "\n",
    "data['DiffKillMaxKill']=data['kills']-data['killsmaxMatch']\n",
    "data['DiffDmgMaxDmg']=data['damageDealt']-data['damageDealtmaxMatch']\n",
    "\n",
    "\n",
    "solo=data[(data.matchType=='solo')]\n",
    "duo=data[(data.matchType=='duo')]\n",
    "squad=data[(data.matchType=='squad')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-suppression des dataframes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del [[mean,maxi,meanG,maxiG,ok,datak]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Id\",\"groupId\",\"matchId\"], axis = 1)\n",
    "data = pd.get_dummies(data, columns=['matchType'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "feat=data.iloc[:,np.r_[0:21, 22:153]]\n",
    "target=data.iloc[:,[21]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-on commence par séparer les données d'apprentissage de test selon la répartition souhaitée  \n",
    "-puis on vient diviser les données d'apprentissage en 10 échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "\n",
    "rs = ShuffleSplit(test_size=0.001, n_splits=1, random_state=0)\n",
    "for train_idx,test_idx in rs.split(feat):  \n",
    "    pass\n",
    "\n",
    "\n",
    "train_split = round(len(train_idx) / 10)\n",
    "train1_idx = train_idx[0:train_split]\n",
    "train2_idx = train_idx[train_split:(2*train_split)]\n",
    "train3_idx = train_idx[(2*train_split):(3*train_split)]\n",
    "train4_idx = train_idx[(3*train_split):(4*train_split)]\n",
    "train5_idx = train_idx[(4*train_split):(5*train_split)]\n",
    "train6_idx = train_idx[(5*train_split):(6*train_split)]\n",
    "train7_idx = train_idx[(6*train_split):(7*train_split)]\n",
    "train8_idx = train_idx[(7*train_split):(8*train_split)]\n",
    "train9_idx = train_idx[(8*train_split):(9*train_split)]\n",
    "train10_idx = train_idx[(9*train_split):(10*train_split)]\n",
    "\n",
    "X_train_1 = feat.loc[train1_idx]\n",
    "X_train_2 = feat.loc[train2_idx]\n",
    "X_train_3 = feat.loc[train3_idx]\n",
    "X_train_4 = feat.loc[train4_idx]\n",
    "X_train_5 = feat.loc[train5_idx]\n",
    "X_train_6 = feat.loc[train6_idx]\n",
    "X_train_7 = feat.loc[train7_idx]\n",
    "X_train_8 = feat.loc[train8_idx]\n",
    "X_train_9 = feat.loc[train9_idx]\n",
    "X_train_10 = feat.loc[train10_idx]\n",
    "X_test=feat.loc[test_idx]\n",
    "\n",
    "y_train_1 = target.loc[train1_idx]\n",
    "y_train_2 = target.loc[train2_idx]\n",
    "y_train_3 = target.loc[train3_idx]\n",
    "y_train_4 = target.loc[train4_idx]\n",
    "y_train_5 = target.loc[train5_idx]\n",
    "y_train_6 = target.loc[train6_idx]\n",
    "y_train_7 = target.loc[train7_idx]\n",
    "y_train_8 = target.loc[train8_idx]\n",
    "y_train_9 = target.loc[train9_idx]\n",
    "y_train_10 = target.loc[train10_idx]\n",
    "y_test=target.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del [[data,feat,target]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-on place les données d'apprentissage et de test dans des objets DMatrix pour être utilisées dans les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
    "xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
    "xg_train_3 = xgb.DMatrix(X_train_3, label=y_train_3)\n",
    "xg_train_4 = xgb.DMatrix(X_train_4, label=y_train_4)\n",
    "xg_train_5 = xgb.DMatrix(X_train_5, label=y_train_5)\n",
    "xg_train_6 = xgb.DMatrix(X_train_6, label=y_train_6)\n",
    "xg_train_7 = xgb.DMatrix(X_train_7, label=y_train_7)\n",
    "xg_train_8 = xgb.DMatrix(X_train_8, label=y_train_8)\n",
    "xg_train_9 = xgb.DMatrix(X_train_9, label=y_train_9)\n",
    "xg_train_10 = xgb.DMatrix(X_train_10, label=y_train_10)\n",
    "\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-initialisation des paramètres et lancement des 10 modèles qui apprennent du précédent via le paramètre xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_round = 100\n",
    "verbose_eval = 5\n",
    "watch_list = [(xg_test, 'xg_test')]\n",
    "\n",
    "params = {'objective': 'reg:squarederror','verbose': False, 'scale_pos_weight':2,'learning_rate':0.1}\n",
    "\n",
    "print('model 1 \\t'); \n",
    "model_1 = xgb.train(params, xg_train_1, num_round,watch_list, verbose_eval=verbose_eval)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, model_1.predict(xg_test)))\n",
    "\n",
    "model_2 = xgb.train(params, xg_train_2, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_1)\n",
    "del model_1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_3 = xgb.train(params, xg_train_3, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_2)\n",
    "del model_2\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_4 = xgb.train(params, xg_train_4, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_3)\n",
    "del model_3\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_5 = xgb.train(params, xg_train_5, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_4)\n",
    "del model_4\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_6 = xgb.train(params, xg_train_6, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_5)\n",
    "del model_5\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_7 = xgb.train(params, xg_train_7, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_6)\n",
    "del model_6\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_8 = xgb.train(params, xg_train_8, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_7)\n",
    "del model_7\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_9 = xgb.train(params, xg_train_9, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_8)\n",
    "del model_8\n",
    "gc.collect()\n",
    "\n",
    "model_10 = xgb.train(params, xg_train_10, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_9)\n",
    "del model_9\n",
    "gc.collect()\n",
    "print('model 10\\t', mse(model_10.predict(xg_test), y_test))# \"after\"\n",
    "\n",
    "model_10.save_model('gdrive/My Drive/model_full.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-on réapplique aux données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gdrive/My Drive/test_V2.csv')\n",
    "\n",
    "data = data.loc[(data['killPlace'] < 101)]\n",
    "data = data.drop([\"DBNOs\",\"maxPlace\",\"winPoints\"], axis = 1)\n",
    "\n",
    "data.loc[(data['matchType']== 'squad-fpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'normal-squad-fpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'normal-squad'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'flarefpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'flaretpp'),'matchType']='squad'\n",
    "\n",
    "data.loc[(data['matchType']== 'duo-fpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']== 'normal-duo-fpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='normal-duo'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='crashfpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='crashtpp'),'matchType']='duo'\n",
    "\n",
    "data.loc[(data['matchType']== 'solo-fpp'),'matchType']='solo'\n",
    "data.loc[(data['matchType']== 'normal-solo-fpp'),'matchType']='solo'\n",
    "data.loc[(data['matchType']== 'normal-solo'),'matchType']='solo'\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "datak = data.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "kmeans = KMeans(n_clusters=7, random_state=0,max_iter=10,n_init=1).fit(datak)\n",
    "data['classe']=kmeans.labels_\n",
    "data['healParDurationM']=data['heals']/data['matchDuration']\n",
    "data['killParDurationM']=data['kills']/data['matchDuration']\n",
    "data['killParRideDist']=data['kills'].divide(data['rideDistance'])\n",
    "data['RideDistParDurationM']=data['rideDistance']/data['matchDuration']\n",
    "data['BoostParKill']=data['boosts'].divide(data['kills'])\n",
    "data['KillParSwimDist']=data['kills'].divide(data['swimDistance'])\n",
    "data['KillParWalkDist']=data['kills'].divide(data['walkDistance'])\n",
    "\n",
    "\n",
    "\n",
    "ok=data.drop([\"matchType\",\"Id\",\"groupId\",\"classe\"], axis = 1)\n",
    "mean=ok.groupby('matchId').mean()\n",
    "maxi=ok.groupby('matchId').max()\n",
    "\n",
    "\n",
    "mean.columns = [x + \"meanMatch\" for x in mean.columns]\n",
    "maxi.columns = [x + \"maxMatch\" for x in maxi.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meanG=ok.groupby('groupId').mean()\n",
    "maxiG=ok.groupby('groupId').max()\n",
    "\n",
    "\n",
    "meanG.columns = [x + \"meanGroupe\" for x in meanG.columns]\n",
    "maxiG.columns = [x + \"maxGroupe\" for x in maxiG.columns]\n",
    "\n",
    "\n",
    "data=data.merge(meanG,on='groupId').merge(maxiG,on='groupId').merge(mean,on='matchId').merge(maxi,on='matchId')\n",
    "\n",
    "\n",
    "data = pd.get_dummies(data, columns=['classe'])\n",
    "data=data.replace([inf], np.nan)\n",
    "data=data.fillna(0)\n",
    "data['DiffKillMaxKill']=data['kills']-data['killsmaxMatch']\n",
    "data['DiffDmgMaxDmg']=data['damageDealt']-data['damageDealtmaxMatch']\n",
    "\n",
    "\n",
    "full = data.drop([\"Id\",\"groupId\",\"matchId\"], axis = 1)\n",
    "full = pd.get_dummies(full, columns=['matchType'])\n",
    "data=data.filter(items=['Id'])\n",
    "full = full.loc[:]\n",
    "full = xgb.DMatrix(full)\n",
    "data['WinPlacePerc']=model_10.predict(full)\n",
    "data=data.filter(items=['Id', 'WinPlacePerc'])\n",
    "\n",
    "data.loc[(data['WinPlacePerc']<0),'WinPlacePerc']=0\n",
    "data.loc[(data['WinPlacePerc']>1),'WinPlacePerc']=1\n",
    "data.to_csv('gdrive/My Drive/SubmitFull.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle par type de match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = squad.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "squad.reset_index(inplace = True)\n",
    "feat=squad.iloc[:,np.r_[1:22, 23:150]]\n",
    "target=squad.iloc[:,[22]]\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "\n",
    "rs = ShuffleSplit(test_size=0.001, n_splits=1, random_state=0)\n",
    "for train_idx,test_idx in rs.split(feat):  # this looks silly\n",
    "    pass\n",
    "\n",
    "\n",
    "train_split = round(len(train_idx) / 10)\n",
    "train1_idx = train_idx[0:train_split]\n",
    "train2_idx = train_idx[train_split:(2*train_split)]\n",
    "train3_idx = train_idx[(2*train_split):(3*train_split)]\n",
    "train4_idx = train_idx[(3*train_split):(4*train_split)]\n",
    "train5_idx = train_idx[(4*train_split):(5*train_split)]\n",
    "train6_idx = train_idx[(5*train_split):(6*train_split)]\n",
    "train7_idx = train_idx[(6*train_split):(7*train_split)]\n",
    "train8_idx = train_idx[(7*train_split):(8*train_split)]\n",
    "train9_idx = train_idx[(8*train_split):(9*train_split)]\n",
    "train10_idx = train_idx[(9*train_split):(10*train_split)]\n",
    "\n",
    "X_train_1 = feat.loc[train1_idx]\n",
    "X_train_2 = feat.loc[train2_idx]\n",
    "X_train_3 = feat.loc[train3_idx]\n",
    "X_train_4 = feat.loc[train4_idx]\n",
    "X_train_5 = feat.loc[train5_idx]\n",
    "X_train_6 = feat.loc[train6_idx]\n",
    "X_train_7 = feat.loc[train7_idx]\n",
    "X_train_8 = feat.loc[train8_idx]\n",
    "X_train_9 = feat.loc[train9_idx]\n",
    "X_train_10 = feat.loc[train10_idx]\n",
    "X_test=feat.loc[test_idx]\n",
    "\n",
    "y_train_1 = target.loc[train1_idx]\n",
    "y_train_2 = target.loc[train2_idx]\n",
    "y_train_3 = target.loc[train3_idx]\n",
    "y_train_4 = target.loc[train4_idx]\n",
    "y_train_5 = target.loc[train5_idx]\n",
    "y_train_6 = target.loc[train6_idx]\n",
    "y_train_7 = target.loc[train7_idx]\n",
    "y_train_8 = target.loc[train8_idx]\n",
    "y_train_9 = target.loc[train9_idx]\n",
    "y_train_10 = target.loc[train10_idx]\n",
    "y_test=target.loc[test_idx]\n",
    "\n",
    "del [[feat,target]]\n",
    "gc.collect()\n",
    "\n",
    "xg_train_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
    "xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
    "xg_train_3 = xgb.DMatrix(X_train_3, label=y_train_3)\n",
    "xg_train_4 = xgb.DMatrix(X_train_4, label=y_train_4)\n",
    "xg_train_5 = xgb.DMatrix(X_train_5, label=y_train_5)\n",
    "xg_train_6 = xgb.DMatrix(X_train_6, label=y_train_6)\n",
    "xg_train_7 = xgb.DMatrix(X_train_7, label=y_train_7)\n",
    "xg_train_8 = xgb.DMatrix(X_train_8, label=y_train_8)\n",
    "xg_train_9 = xgb.DMatrix(X_train_9, label=y_train_9)\n",
    "xg_train_10 = xgb.DMatrix(X_train_10, label=y_train_10)\n",
    "\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "num_round = 100\n",
    "verbose_eval = 5\n",
    "watch_list = [(xg_test, 'xg_test')]\n",
    "\n",
    "params = {'objective': 'reg:squarederror','verbose': False, 'scale_pos_weight':2,'learning_rate':0.1}\n",
    "\n",
    "print('model 1 \\t'); \n",
    "model_1 = xgb.train(params, xg_train_1, num_round,watch_list, verbose_eval=verbose_eval)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, model_1.predict(xg_test)))\n",
    "\n",
    "\n",
    "model_2 = xgb.train(params, xg_train_2, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_1)\n",
    "del model_1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_3 = xgb.train(params, xg_train_3, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_2)\n",
    "del model_2\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_4 = xgb.train(params, xg_train_4, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_3)\n",
    "del model_3\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_5 = xgb.train(params, xg_train_5, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_4)\n",
    "del model_4\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_6 = xgb.train(params, xg_train_6, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_5)\n",
    "del model_5\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_7 = xgb.train(params, xg_train_7, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_6)\n",
    "del model_6\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_8 = xgb.train(params, xg_train_8, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_7)\n",
    "del model_7\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_9 = xgb.train(params, xg_train_9, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_8)\n",
    "del model_8\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_squad = xgb.train(params, xg_train_10, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_9)\n",
    "del model_9\n",
    "gc.collect()\n",
    "print('model 10\\t', mse(model_squad.predict(xg_test), y_test))# \"after\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duo = duo.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "duo.reset_index(inplace = True)\n",
    "feat=duo.iloc[:,np.r_[1:22, 23:150]]\n",
    "target=duo.iloc[:,[22]]\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "\n",
    "rs = ShuffleSplit(test_size=0.001, n_splits=1, random_state=0)\n",
    "for train_idx,test_idx in rs.split(feat):  # this looks silly\n",
    "    pass\n",
    "\n",
    "\n",
    "train_split = round(len(train_idx) / 10)\n",
    "train1_idx = train_idx[0:train_split]\n",
    "train2_idx = train_idx[train_split:(2*train_split)]\n",
    "train3_idx = train_idx[(2*train_split):(3*train_split)]\n",
    "train4_idx = train_idx[(3*train_split):(4*train_split)]\n",
    "train5_idx = train_idx[(4*train_split):(5*train_split)]\n",
    "train6_idx = train_idx[(5*train_split):(6*train_split)]\n",
    "train7_idx = train_idx[(6*train_split):(7*train_split)]\n",
    "train8_idx = train_idx[(7*train_split):(8*train_split)]\n",
    "train9_idx = train_idx[(8*train_split):(9*train_split)]\n",
    "train10_idx = train_idx[(9*train_split):(10*train_split)]\n",
    "\n",
    "X_train_1 = feat.loc[train1_idx]\n",
    "X_train_2 = feat.loc[train2_idx]\n",
    "X_train_3 = feat.loc[train3_idx]\n",
    "X_train_4 = feat.loc[train4_idx]\n",
    "X_train_5 = feat.loc[train5_idx]\n",
    "X_train_6 = feat.loc[train6_idx]\n",
    "X_train_7 = feat.loc[train7_idx]\n",
    "X_train_8 = feat.loc[train8_idx]\n",
    "X_train_9 = feat.loc[train9_idx]\n",
    "X_train_10 = feat.loc[train10_idx]\n",
    "X_test=feat.loc[test_idx]\n",
    "\n",
    "y_train_1 = target.loc[train1_idx]\n",
    "y_train_2 = target.loc[train2_idx]\n",
    "y_train_3 = target.loc[train3_idx]\n",
    "y_train_4 = target.loc[train4_idx]\n",
    "y_train_5 = target.loc[train5_idx]\n",
    "y_train_6 = target.loc[train6_idx]\n",
    "y_train_7 = target.loc[train7_idx]\n",
    "y_train_8 = target.loc[train8_idx]\n",
    "y_train_9 = target.loc[train9_idx]\n",
    "y_train_10 = target.loc[train10_idx]\n",
    "y_test=target.loc[test_idx]\n",
    "\n",
    "del [[feat,target]]\n",
    "gc.collect()\n",
    "\n",
    "xg_train_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
    "xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
    "xg_train_3 = xgb.DMatrix(X_train_3, label=y_train_3)\n",
    "xg_train_4 = xgb.DMatrix(X_train_4, label=y_train_4)\n",
    "xg_train_5 = xgb.DMatrix(X_train_5, label=y_train_5)\n",
    "xg_train_6 = xgb.DMatrix(X_train_6, label=y_train_6)\n",
    "xg_train_7 = xgb.DMatrix(X_train_7, label=y_train_7)\n",
    "xg_train_8 = xgb.DMatrix(X_train_8, label=y_train_8)\n",
    "xg_train_9 = xgb.DMatrix(X_train_9, label=y_train_9)\n",
    "xg_train_10 = xgb.DMatrix(X_train_10, label=y_train_10)\n",
    "\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "num_round = 100\n",
    "verbose_eval = 5\n",
    "watch_list = [(xg_test, 'xg_test')]\n",
    "\n",
    "params = {'objective': 'reg:squarederror','verbose': False, 'scale_pos_weight':2,'learning_rate':0.1}\n",
    "\n",
    "print('model 1 \\t'); \n",
    "model_1 = xgb.train(params, xg_train_1, num_round,watch_list, verbose_eval=verbose_eval)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, model_1.predict(xg_test)))\n",
    "\n",
    "\n",
    "model_2 = xgb.train(params, xg_train_2, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_1)\n",
    "del model_1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_3 = xgb.train(params, xg_train_3, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_2)\n",
    "del model_2\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_4 = xgb.train(params, xg_train_4, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_3)\n",
    "del model_3\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_5 = xgb.train(params, xg_train_5, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_4)\n",
    "del model_4\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_6 = xgb.train(params, xg_train_6, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_5)\n",
    "del model_5\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_7 = xgb.train(params, xg_train_7, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_6)\n",
    "del model_6\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_8 = xgb.train(params, xg_train_8, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_7)\n",
    "del model_7\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_9 = xgb.train(params, xg_train_9, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_8)\n",
    "del model_8\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_duo = xgb.train(params, xg_train_10, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_9)\n",
    "del model_9\n",
    "gc.collect()\n",
    "print('model 10\\t', mse(model_duo.predict(xg_test), y_test))# \"after\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = solo.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "solo.reset_index(inplace = True)\n",
    "feat=solo.iloc[:,np.r_[1:22, 23:150]]\n",
    "target=solo.iloc[:,[22]]\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "\n",
    "rs = ShuffleSplit(test_size=0.001, n_splits=1, random_state=0)\n",
    "for train_idx,test_idx in rs.split(feat):  # this looks silly\n",
    "    pass\n",
    "\n",
    "\n",
    "train_split = round(len(train_idx) / 10)\n",
    "train1_idx = train_idx[0:train_split]\n",
    "train2_idx = train_idx[train_split:(2*train_split)]\n",
    "train3_idx = train_idx[(2*train_split):(3*train_split)]\n",
    "train4_idx = train_idx[(3*train_split):(4*train_split)]\n",
    "train5_idx = train_idx[(4*train_split):(5*train_split)]\n",
    "train6_idx = train_idx[(5*train_split):(6*train_split)]\n",
    "train7_idx = train_idx[(6*train_split):(7*train_split)]\n",
    "train8_idx = train_idx[(7*train_split):(8*train_split)]\n",
    "train9_idx = train_idx[(8*train_split):(9*train_split)]\n",
    "train10_idx = train_idx[(9*train_split):(10*train_split)]\n",
    "\n",
    "X_train_1 = feat.loc[train1_idx]\n",
    "X_train_2 = feat.loc[train2_idx]\n",
    "X_train_3 = feat.loc[train3_idx]\n",
    "X_train_4 = feat.loc[train4_idx]\n",
    "X_train_5 = feat.loc[train5_idx]\n",
    "X_train_6 = feat.loc[train6_idx]\n",
    "X_train_7 = feat.loc[train7_idx]\n",
    "X_train_8 = feat.loc[train8_idx]\n",
    "X_train_9 = feat.loc[train9_idx]\n",
    "X_train_10 = feat.loc[train10_idx]\n",
    "X_test=feat.loc[test_idx]\n",
    "\n",
    "y_train_1 = target.loc[train1_idx]\n",
    "y_train_2 = target.loc[train2_idx]\n",
    "y_train_3 = target.loc[train3_idx]\n",
    "y_train_4 = target.loc[train4_idx]\n",
    "y_train_5 = target.loc[train5_idx]\n",
    "y_train_6 = target.loc[train6_idx]\n",
    "y_train_7 = target.loc[train7_idx]\n",
    "y_train_8 = target.loc[train8_idx]\n",
    "y_train_9 = target.loc[train9_idx]\n",
    "y_train_10 = target.loc[train10_idx]\n",
    "y_test=target.loc[test_idx]\n",
    "\n",
    "del [[feat,target]]\n",
    "gc.collect()\n",
    "\n",
    "xg_train_1 = xgb.DMatrix(X_train_1, label=y_train_1)\n",
    "xg_train_2 = xgb.DMatrix(X_train_2, label=y_train_2)\n",
    "xg_train_3 = xgb.DMatrix(X_train_3, label=y_train_3)\n",
    "xg_train_4 = xgb.DMatrix(X_train_4, label=y_train_4)\n",
    "xg_train_5 = xgb.DMatrix(X_train_5, label=y_train_5)\n",
    "xg_train_6 = xgb.DMatrix(X_train_6, label=y_train_6)\n",
    "xg_train_7 = xgb.DMatrix(X_train_7, label=y_train_7)\n",
    "xg_train_8 = xgb.DMatrix(X_train_8, label=y_train_8)\n",
    "xg_train_9 = xgb.DMatrix(X_train_9, label=y_train_9)\n",
    "xg_train_10 = xgb.DMatrix(X_train_10, label=y_train_10)\n",
    "\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "num_round = 100\n",
    "verbose_eval = 5\n",
    "watch_list = [(xg_test, 'xg_test')]\n",
    "\n",
    "params = {'objective': 'reg:squarederror','verbose': False, 'scale_pos_weight':2,'learning_rate':0.1}\n",
    "\n",
    "print('model 1 \\t'); \n",
    "model_1 = xgb.train(params, xg_train_1, num_round,watch_list, verbose_eval=verbose_eval)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, model_1.predict(xg_test)))\n",
    "\n",
    "\n",
    "model_2 = xgb.train(params, xg_train_2, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_1)\n",
    "del model_1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_3 = xgb.train(params, xg_train_3, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_2)\n",
    "del model_2\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_4 = xgb.train(params, xg_train_4, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_3)\n",
    "del model_3\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_5 = xgb.train(params, xg_train_5, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_4)\n",
    "del model_4\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_6 = xgb.train(params, xg_train_6, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_5)\n",
    "del model_5\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_7 = xgb.train(params, xg_train_7, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_6)\n",
    "del model_6\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_8 = xgb.train(params, xg_train_8, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_7)\n",
    "del model_7\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_9 = xgb.train(params, xg_train_9, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_8)\n",
    "del model_8\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_solo = xgb.train(params, xg_train_10, num_round,watch_list, verbose_eval=verbose_eval, xgb_model=model_9)\n",
    "del model_9\n",
    "gc.collect()\n",
    "print('model 10\\t', mse(model_solo.predict(xg_test), y_test))# \"after\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on réapplique aux données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('gdrive/My Drive/test_V2.csv')\n",
    "\n",
    "data = data.loc[(data['killPlace'] < 101)]\n",
    "data = data.drop([\"DBNOs\",\"maxPlace\",\"winPoints\"], axis = 1)\n",
    "\n",
    "data.loc[(data['matchType']== 'squad-fpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'normal-squad-fpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'normal-squad'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'flarefpp'),'matchType']='squad'\n",
    "data.loc[(data['matchType']== 'flaretpp'),'matchType']='squad'\n",
    "\n",
    "data.loc[(data['matchType']== 'duo-fpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']== 'normal-duo-fpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='normal-duo'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='crashfpp'),'matchType']='duo'\n",
    "data.loc[(data['matchType']=='crashtpp'),'matchType']='duo'\n",
    "\n",
    "data.loc[(data['matchType']== 'solo-fpp'),'matchType']='solo'\n",
    "data.loc[(data['matchType']== 'normal-solo-fpp'),'matchType']='solo'\n",
    "data.loc[(data['matchType']== 'normal-solo'),'matchType']='solo'\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "datak = data.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "kmeans = KMeans(n_clusters=7, random_state=0,max_iter=10,n_init=1).fit(datak)\n",
    "data['classe']=kmeans.labels_\n",
    "data['healParDurationM']=data['heals']/data['matchDuration']\n",
    "data['killParDurationM']=data['kills']/data['matchDuration']\n",
    "data['killParRideDist']=data['kills'].divide(data['rideDistance'])\n",
    "data['RideDistParDurationM']=data['rideDistance']/data['matchDuration']\n",
    "data['BoostParKill']=data['boosts'].divide(data['kills'])\n",
    "data['KillParSwimDist']=data['kills'].divide(data['swimDistance'])\n",
    "data['KillParWalkDist']=data['kills'].divide(data['walkDistance'])\n",
    "\n",
    "\n",
    "ok=data.drop([\"matchType\",\"Id\",\"groupId\",\"classe\"], axis = 1)\n",
    "mean=ok.groupby('matchId').mean()\n",
    "maxi=ok.groupby('matchId').max()\n",
    "\n",
    "\n",
    "mean.columns = [x + \"meanMatch\" for x in mean.columns]\n",
    "maxi.columns = [x + \"maxMatch\" for x in maxi.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "meanG=ok.groupby('groupId').mean()\n",
    "maxiG=ok.groupby('groupId').max()\n",
    "\n",
    "\n",
    "meanG.columns = [x + \"meanGroupe\" for x in meanG.columns]\n",
    "maxiG.columns = [x + \"maxGroupe\" for x in maxiG.columns]\n",
    "\n",
    "\n",
    "data=data.merge(meanG,on='groupId').merge(maxiG,on='groupId').merge(mean,on='matchId').merge(maxi,on='matchId')\n",
    "\n",
    "\n",
    "data = pd.get_dummies(data, columns=['classe'])\n",
    "data=data.replace([inf], np.nan)\n",
    "data=data.fillna(0)\n",
    "data['DiffKillMaxKill']=data['kills']-data['killsmaxMatch']\n",
    "data['DiffDmgMaxDmg']=data['damageDealt']-data['damageDealtmaxMatch']\n",
    "\n",
    "solo=data[(data.matchType=='solo')]\n",
    "duo=data[(data.matchType=='duo')]\n",
    "squad=data[(data.matchType=='squad')]\n",
    "\n",
    "squadtest = squad.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "squadtest.reset_index(inplace = True)\n",
    "del squadtest['index']\n",
    "squadtest = squadtest.loc[:]\n",
    "squadtest = xgb.DMatrix(squadtest)\n",
    "squad['WinPlacePerc']=model_squad.predict(squadtest)\n",
    "squad=squad.filter(items=['Id', 'WinPlacePerc'])\n",
    "\n",
    "duotest = duo.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "duotest.reset_index(inplace = True)\n",
    "del duotest['index']\n",
    "duotest = duotest.loc[:]\n",
    "duotest = xgb.DMatrix(duotest)\n",
    "duo['WinPlacePerc']=model_duo.predict(duotest)\n",
    "duo=duo.filter(items=['Id', 'WinPlacePerc'])\n",
    "\n",
    "solotest = solo.drop([\"Id\",\"groupId\",\"matchId\",\"matchType\"], axis = 1)\n",
    "solotest.reset_index(inplace = True)\n",
    "del solotest['index']\n",
    "solotest = solotest.loc[:]\n",
    "solotest = xgb.DMatrix(solotest)\n",
    "solo['WinPlacePerc']=model_solo.predict(solotest)\n",
    "solo=solo.filter(items=['Id', 'WinPlacePerc'])\n",
    "\n",
    "data=pd.concat([squad, duo,solo], ignore_index=True)\n",
    "data.loc[(data['WinPlacePerc']<0),'WinPlacePerc']=0\n",
    "data.loc[(data['WinPlacePerc']>1),'WinPlacePerc']=1\n",
    "data.to_csv('gdrive/My Drive/Submit_teamMatch.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
